{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *IPCC SR15 scenario assessment*\n",
    "\n",
    "<img style=\"float: right; height: 80px; padding-left: 20px;\" src=\"../_static/IIASA_logo.png\">\n",
    "<img style=\"float: right; height: 80px;\" src=\"../_static/IAMC_logo.jpg\">\n",
    "\n",
    "# Geophysical characteristics of mitigation pathways\n",
    "\n",
    "This notebook computes Ggeophysical characteristics of mitigation pathways in the IPCC's _\"Special Report on Global Warming of 1.5°C\"_. The notebook generates the data for **Table 2.SM.12** in the Special Report.\n",
    "\n",
    "The scenario data used in this analysis can be accessed and downloaded at [https://data.ene.iiasa.ac.at/iamc-1.5c-explorer](https://data.ene.iiasa.ac.at/iamc-1.5c-explorer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `pyam` package and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pyam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import scenario data, categorization and specifications files\n",
    "\n",
    "The metadata file must be generated from the notebook `sr15_2.0_categories_indicators` included in this repository.  \n",
    "If the snapshot file has been updated, make sure that you rerun the categorization notebook.\n",
    "\n",
    "The last cell of this section loads and assigns a number of auxiliary lists as defined in the categorization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1p5 = pyam.IamDataFrame(data='../data/iamc15_scenario_data_world_r1.1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1p5.load_metadata('sr15_metadata_indicators.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sr15_specs.yaml\", 'r') as stream:\n",
    "    specs = yaml.load(stream)\n",
    "\n",
    "cats = specs.pop('cats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downselect scenario ensemble to categories of interest for this assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1p5.meta.rename(columns={'Kyoto-GHG|2010 (SAR)': 'kyoto_ghg_2010'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_args_aim = dict(model='AIM*',\n",
    "                       scenario=['SFCM*_1p5Degree', 'EMF33_Med2C_nofuel', 'EMF33_Med2C_none'],\n",
    "                       keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    sr1p5\n",
    "    .filter(kyoto_ghg_2010='in range', category=cats)\n",
    "    .filter(**filter_args_aim)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a `pyam.Statistics` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pyam.Statistics(df=df, groupby={'category': cats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.add(df.meta['year of netzero CO2 emissions'],\n",
    "          header='', subheader='Year of net-zero CO2 emissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_peak = {'header': 'Geophysical characteristics at Peak Warming'}\n",
    "header_2100 = {'header': 'Geophysical characteristics in 2100'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.add(df.meta['median warming at peak (MAGICC6)'],\n",
    "          **header_peak, subheader='Peak|Median warming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_year = 'year of peak warming (MAGICC6)'\n",
    "stats.add(df.meta[peak_year], **header_peak, subheader='Peak|Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicator(stats, data, subheader=None, df=df,\n",
    "                  year=['Peak', 2100], headers=[header_peak, header_2100]):\n",
    "    for y, h in zip(year, headers):\n",
    "        if y == 'Peak':\n",
    "            values = data.apply(lambda x: x[df.meta.loc[x.name[0:2]][peak_year]],\n",
    "                              raw=False, axis=1)\n",
    "        else:\n",
    "            values = data.apply(lambda x: x[y], raw=False, axis=1)\n",
    "        stats.add(values, **h, subheader='{}|{}'.format(y, subheader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 'AR5 climate diagnostics|Concentration|CO2|MAGICC6|MED'\n",
    "sh = 'CO2 [ppm]'\n",
    "co2_concentation = df.filter(variable=v).timeseries()\n",
    "add_indicator(stats, co2_concentation, sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 'AR5 climate diagnostics|Forcing|MAGICC6|MED'\n",
    "sh = 'RF all [Wm2]'\n",
    "rf_all = df.filter(variable=v).timeseries()\n",
    "add_indicator(stats, rf_all, sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 'AR5 climate diagnostics|Forcing|CO2|MAGICC6|MED'\n",
    "sh = 'RF CO2 [Wm2]'\n",
    "rf_co2 = df.filter(variable=v).timeseries()\n",
    "add_indicator(stats, rf_co2, sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = 'RF non-CO2 [Wm2]'\n",
    "rf_all.index = rf_all.index.droplevel([2, 3, 4])\n",
    "rf_co2.index = rf_co2.index.droplevel([2, 3, 4])\n",
    "rf_non_co2 = rf_all - rf_co2\n",
    "add_indicator(stats, rf_non_co2, sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (h, n) in [(header_peak, '2016 to peak warming'),\n",
    "               (header_2100, '2016-2100')]:\n",
    "\n",
    "    stats.add(df.meta['cumulative CO2 emissions ({}, Gt CO2)'.format(n)], **h,\n",
    "              subheader='cumulative CO2 emissions ({}, as submitted) [GtCO2]'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonized_co2_vars = [\n",
    "    'Diagnostics|MAGICC6|Harmonized Input|Emissions|CO2|Energy and Industrial Processes',\n",
    "    'Diagnostics|MAGICC6|Harmonized Input|Emissions|CO2|AFOLU'\n",
    "]\n",
    "\n",
    "harmonized_co2 = (\n",
    "    df.filter(variable=harmonized_co2_vars, year=range(2010, 2101, 10))\n",
    "    .timeseries()\n",
    "    .groupby(['model', 'scenario'])\n",
    "    .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseyear = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_harmonized_co2 = (\n",
    "    harmonized_co2.apply(lambda x:\n",
    "        pyam.cumulative(x, first_year=baseyear,\n",
    "                        last_year=df.meta.loc[x.name[0:2]][peak_year]) / 1000,\n",
    "        raw=False, axis=1\n",
    "    )\n",
    ")\n",
    "stats.add(peak_harmonized_co2, **header_peak,\n",
    "          subheader='cumulative CO2 emissions (2016 to peak warming, harmonized) [GtCO2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eoc_harmonized_co2 = (\n",
    "    harmonized_co2.apply(lambda x:\n",
    "        pyam.cumulative(x, first_year=baseyear, last_year=2100) / 1000,\n",
    "        raw=False, axis=1\n",
    "    )\n",
    ")\n",
    "stats.add(eoc_harmonized_co2, **header_2100,\n",
    "          subheader='cumulative CO2 emissions (2016-2100, harmonized) [GtCO2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_prob = {}\n",
    "for t in [1.5, 2.0, 2.5]:\n",
    "    v = 'AR5 climate diagnostics|Temperature|Exceedance Probability|{} °C|MAGICC6'.format(t)\n",
    "    sh = 'Exceedance Probability {} [%]'.format(t)\n",
    "    ex_prob = df.filter(variable=v).timeseries() * 100\n",
    "    add_indicator(stats, ex_prob, sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overshoot severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_overshoot = {'header': 'Geophysical Characteristics of the Temperature Overshoot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'AR5 climate diagnostics|Temperature|Global Mean|MAGICC6|MED'\n",
    "\n",
    "mean_temperature = (\n",
    "    df.filter(variable=variable)\n",
    "    .timeseries()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exceedance(temperature, threshold):\n",
    "    years = pyam.cross_threshold(temperature, threshold)\n",
    "    \n",
    "    exceedance_yr = years[0] if len(years) else np.nan\n",
    "    return_yr = years[1] if len(years) > 1 else np.nan\n",
    "    overshoot_yr_count = return_yr - exceedance_yr\n",
    "\n",
    "    if not np.isnan(overshoot_yr_count):\n",
    "         severity = (\n",
    "             pyam.cumulative(temperature, exceedance_yr, return_yr)\n",
    "             - (overshoot_yr_count + 1) * threshold)\n",
    "    else:\n",
    "        severity = np.nan\n",
    "\n",
    "    return [exceedance_yr, return_yr, overshoot_yr_count, severity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in mean_temperature.index:\n",
    "    lst.append(pd.DataFrame(exceedance(mean_temperature.loc[i], 1.5)).T)\n",
    "\n",
    "ex_years_15 = pd.concat(lst)\n",
    "ex_years_15.index = mean_temperature.index\n",
    "ex_years_15.columns = ['Exceedance year', 'Return year', 'Overshoot years', 'Overshoot severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in mean_temperature.index:\n",
    "    lst.append(pd.DataFrame(exceedance(mean_temperature.loc[i], 2.0)).T)\n",
    "\n",
    "ex_years_20 = pd.concat(lst)\n",
    "ex_years_20.index = mean_temperature.index\n",
    "ex_years_20.columns = ['Exceedance year', 'Return year', 'Overshoot years', 'Overshoot severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.add(ex_years_15['Exceedance year'], **header_overshoot,\n",
    "          subheader='Exceedance year|1.5°C [year]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.add(ex_years_20['Exceedance year'], **header_overshoot,\n",
    "          subheader='Exceedance year|2.0°C [year]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.add(ex_years_15['Overshoot years'], **header_overshoot,\n",
    "          subheader='Overshoot duration|1.5°C [number of years]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.add(ex_years_20['Overshoot years'], **header_overshoot,\n",
    "          subheader='Overshoot duration|2.0°C [number of years]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.add(ex_years_15['Overshoot severity'], **header_overshoot,\n",
    "          subheader='Overshoot severity|1.5°C [temperature-years]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display and export summary statistics to `xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = stats.summarize(center='median', interquartile=True, custom_format='{:.1f}')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_excel('output/table_2.SM.12_geophysical_characteristics.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
